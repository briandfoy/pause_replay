{
   "data" : {
      "userid" : {
         "name" : "Lin Yung-Chung",
         "id" : "XERN"
      },
      "description" : "WWW robot plus text analyzer",
      "communities" : "comp.lang.perl.modules",
      "chapterid" : {
         "name" : "World_Wide_Web_HTML_HTTP_CGI",
         "id" : "15"
      },
      "similar" : "LWP HTML::TreeBuilder WWW::Search WWW::Robot",
      "DSLIP" : "aupha",
      "modid" : "WWW::FilterRobot",
      "enteredon" : "Sat Nov 30 18:10:30 2002 GMT",
      "enteredby" : {
         "name" : "Lin Yung-Chung",
         "id" : "XERN"
      },
      "PS" : "The following links are only valid for module list maintainers:",
      "rationale" : "Just Like what I've written for WWW::SpiTract before.\n\n    WWW::FilterRobot combines LWP and HTML::TreeBuilder together. Users\n    can write descriptions for specific sites and this module can\n    automatically fetch pages with some attributes in common and extract\n    data as assigned. Users can also write callback functions to\n    manipulate retrieved data. Metasearch engine, personal news center,\n    or price comparison engine, for example, can be easily built upon\n    this.\n\n    WWW::Search is mainly designed for search engines, but\n    WWW::FilterRobot is more for general uses. WWW::Robot deals with\n    links in a page, not for general purposes either."
   },
   "meta" : {
      "message_id" : "200211301810.gAUIAV100616@pause.perl.org",
      "epoch" : 1038679831,
      "from" : "upload@p11.speed-link.de",
      "subject" : "Module submission WWW::FilterRobot",
      "file" : "15638.txt",
      "type" : "module_submission"
   }
}
