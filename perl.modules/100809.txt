Newsgroups: perl.modules
Path: nntp.perl.org
Xref: nntp.perl.org perl.modules:100809
Return-Path: <i@ry.ca>
Mailing-List: contact modules-help@perl.org; run by ezmlm
Delivered-To: mailing list modules@perl.org
Received: (qmail 1139 invoked from network); 17 Jan 2020 00:39:21 -0000
Received: from xx1.develooper.com (147.75.38.233) by x6.develooper.com with
 SMTP; 17 Jan 2020 00:39:21 -0000
Received: from localhost (xx1.develooper.com [127.0.0.1]) by localhost
 (Postfix) with ESMTP id 57FA47C1AE for <perlmail-modules@onion.perl.org>;
 Thu, 16 Jan 2020 16:39:21 -0800 (PST)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mx3.develooper.com
X-Spam-Status: No, score=-1.9 required=6.0 tests=BAYES_00,HTML_MESSAGE
 autolearn=ham version=3.3.1
Received: from xx1.develooper.com (xx1.develooper.com [127.0.0.1]) by
 localhost (Postfix) with SMTP id F2CB77C1C1 for
 <perlmail-modules@onion.perl.org>; Thu, 16 Jan 2020 16:39:18 -0800 (PST)
Received: from em.ry.ca (em.ry.ca [75.101.163.7]) by xx1.develooper.com
 (Postfix) with ESMTP id A28177C1AE for <modules@perl.org>; Thu, 16 Jan 2020
 16:39:18 -0800 (PST)
Received: from [10.99.0.3] (unknown [204.83.11.235]) by em.ry.ca (Postfix)
 with ESMTPSA id 819DB613C; Thu, 16 Jan 2020 18:28:14 -0600 (CST)
Subject: Re: TimeDate and indexing permissions
To: Neil Bowers <neil.bowers@cogendo.com>, rjt@cpan.org, Shlomi Fish
 <shlomif@shlomifish.org>
Cc: "PAUSE Admins (Public)" <modules@perl.org>
References: <4243450e-9f91-4cf4-9689-5278ff61f530@Spark>
 <4b510051-9bcf-4092-8b10-438f3eeecc3a@Spark>
Message-ID: <f8c0eb61-5eb8-f17c-7771-754293ebdbc8@ry.ca>
Date: Thu, 16 Jan 2020 18:39:14 -0600
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101
 Thunderbird/68.3.1
MIME-Version: 1.0
In-Reply-To: <4b510051-9bcf-4092-8b10-438f3eeecc3a@Spark>
Content-Type: multipart/alternative; boundary="------------B0C6BFDC3C511879B4AFFD1F"
Content-Language: en-US
X-PMX-Version: 5.6.1.2065439, Antispam-Engine: 2.7.2.376379, Antispam-Data:
 2019.11.28.70017
X-PMX-Spam: Gauge=IIIIIIII, Probability=8%, Report=' HTML_NO_HTTP 0.1,
 BODYTEXTH_SIZE_10000_LESS 0, BODYTEXTP_SIZE_3000_LESS 0, BODY_SIZE_4000_4999
 0, BODY_SIZE_5000_LESS 0, BODY_SIZE_7000_LESS 0, DATE_TZ_NA 0, FROM_MALFORMED
 0, IN_REP_TO 0, LEGITIMATE_SIGNS 0, MSG_THREAD 0, MULTIPLE_REAL_RCPTS 0,
 NO_CTA_FOUND 0, NO_CTA_URI_FOUND 0, NO_URI_FOUND 0, NO_URI_HTTPS 0,
 REFERENCES 0, SPF_PASS 0, __BAT_BOUNDARY 0, __BODY_NO_MAILTO 0,
 __BODY_TEXT_X4 0, __BOUNCE_CHALLENGE_SUBJ 0, __BOUNCE_NDR_SUBJ_EXEMPT 0,
 __CC_NAME 0, __CC_NAME_DIFF_FROM_ACC 0, __CC_REAL_NAMES 0, __CT 0,
 __CTYPE_HAS_BOUNDARY 0, __CTYPE_MULTIPART 0, __CTYPE_MULTIPART_ALT 0,
 __DQ_NEG_HEUR 0, __DQ_NEG_IP 0, __FORWARDED_MSG 0, __FRAUD_INTRO 0,
 __HAS_CC_HDR 0, __HAS_FROM 0, __HAS_HTML 0, __HAS_MSGID 0, __HAS_REFERENCES
 0, __HTML_TAG_DIV 0, __INVOICE_MULTILINGUAL 0, __IN_REP_TO 0, __MIME_HTML 0,
 __MIME_TEXT_H 0, __MIME_TEXT_H1 0, __MIME_TEXT_H2 0, __MIME_TEXT_P 0,
 __MIME_TEXT_P1 0, __MIME_TEXT_P2 0, __MIME_VERSION 0, __MOZILLA_USER_AGENT 0,
 __PHISH_SPEAR_GREETING 0, __REFERENCES 0, __SANE_MSGID 0, __SUBJ_ALPHA_NEGATE
 0, __SUBJ_REPLY 0, __TAG_EXISTS_HTML 0, __TO_MALFORMED_2 0, __TO_NAME 0,
 __TO_NAME_DIFF_FROM_ACC 0, __TO_REAL_NAMES 0, __URI_NO_MAILTO 0, __USER_AGENT
 0, __blackholes.mail-abuse.org_ERROR , __zen.spamhaus.org_ERROR '
Approved: news@nntp.perl.org
From: i@ry.ca (Ryan Thompson)

--------------B0C6BFDC3C511879B4AFFD1F
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit

Hi Neil,

On 2020-01-16 5:04 p.m., Neil Bowers wrote:
> This also points out that we could do with some kind of monitoring 
> system, to spots sudden changes in CPAN test results (without a new 
> release). In this case lots of people noticed that things started 
> failing, but earlier warning in the right place would be useful.

I maintain about 100 CPAN dists for my employer (not on this account), 
and that was starting to get a bit unwieldy, so I came up with a system 
similar, I think, to the one you are proposing. I parse and store the 
CPAN Testers log data to check for recent failures (with some simple 
heuristics in case one tester is having trouble, as sometimes happens). 
If there are failures on any of the modules, it generates an email 
report linking to the failed distribution(s).

Since everything is done off of a local database, scaling to hundreds of 
thousands of distributions is no problem performance-wise. Adjusting the 
output a bit will of course be necessary, but there is opportunity to, 
say, look for only "new" failures like you suggest, send emails to the 
author(s), send either a summary email to modules@, or a "hot topics" 
report that looks at failures + reverse deps over threshold to really 
light a fire under modules like TimeDate that need more immediate attention.

Is anyone already working on something similar? If not, would there be 
interest from the admins in having me adapt what I've done?

- R


--------------B0C6BFDC3C511879B4AFFD1F
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 7bit

<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>
  <body>
    <p><font face="Verdana">Hi Neil,</font></p>
    On 2020-01-16 5:04 p.m., Neil Bowers wrote:<br>
    <blockquote type="cite"
      cite="mid:4b510051-9bcf-4092-8b10-438f3eeecc3a@Spark">
      <meta http-equiv="content-type" content="text/html; charset=UTF-8">
      <title></title>
      <div name="messageBodySection"><font size="3">This also points out
          that we could do with some kind of monitoring system, to spots
          sudden changes in CPAN test results (without a new release).
          In this case lots of people noticed that things started
          failing, but earlier warning in the right place would be
          useful.</font>
      </div>
    </blockquote>
    <p><font face="Verdana">I maintain about 100 CPAN dists for my
        employer (not on this account), and that was starting to get a
        bit unwieldy, so I came up with a system similar, I think, to
        the one you are proposing. I parse and store the CPAN Testers
        log data to check for recent failures (with some simple
        heuristics in case one tester is having trouble, as sometimes
        happens). If there are failures on any of the modules, it
        generates an email report linking to the failed distribution(s).<br>
      </font></p>
    <p><font face="Verdana">Since everything is done off of a local
        database, scaling to hundreds of thousands of distributions is
        no problem performance-wise. Adjusting the output a bit will of
        course be necessary, but there is opportunity to, say, look for
        only "new" failures like you suggest, send emails to the
        author(s), send either a summary email to modules@, or a "hot
        topics" report that looks at failures + reverse deps over
        threshold to really light a fire under modules like TimeDate
        that need more immediate attention.<br>
      </font></p>
    <p><font face="Verdana">Is anyone already working on something
        similar? If not, would there be interest from the admins in
        having me adapt what I've done?<br>
      </font></p>
    <p><font face="Verdana">- R<br>
      </font></p>
  </body>
</html>

--------------B0C6BFDC3C511879B4AFFD1F--
